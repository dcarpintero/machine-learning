# Foundational AI Concepts and Models

<p align="center">
  <img src="/img/dall-e-ai.png" width="200">
</p>

# Large Language Models (LLMs)

- [Transformer: The Building Block for NLP Models](./Transformer.md)
- [BERT: Bidirectional Encoder Representations from Transformers](./BERT.md)
- [RoBERTa: A Robustly Optimized BERT Pretraining Approach](./RoBERTa.md)
- [ALBERT: A Lite BERT for Self-Supervised Learning of Language Representations](./ALBERT.md)
- [DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter](./DistilBERT.md)
- [GPT-3](./GPT-3.md)

# Generative-AI

- [Diffusion Models](./Diffusion-Models.md)
- [Fine-Tuning](./FineTuning.md)

# Deep Reinforcement Learning

- [Introduction](./reinforcement-learning/introduction.md)
- [Q-Learning](./reinforcement-learning/Q-Learning.md)
- [MARL](./reinforcement-learning/MARL.md)

# Credits

- [Introduction to Deep Learning, MIT](http://introtodeeplearning.com/)
- [Deep Reinforcement Learning Course, HuggingFace](https://huggingface.co/learn/deep-rl-course/)
- [Introduction to RL and Deep Q Networks, TensorFlow](https://www.tensorflow.org/agents/tutorials/0_intro_rl)
- []

The background image has been generated by [DALLÂ·E 2](https://openai.com/dall-e-2/) with the prompt "*two data scientists working in a sunny computer lab with plants in the background, digital art*".